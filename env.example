# Notion API Integration Token
# Obtenez-le depuis https://www.notion.so/my-integrations
# Format: ntn_xxxxxxxxxxxxx (nouveau format) ou secret_xxxxx (ancien format)
NOTION_TOKEN=ntn_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Port du serveur HTTP (par défaut: 3000)
PORT=3000

# Optionnel: Token d'authentification pour sécuriser l'accès HTTP
# Si non défini, un token sera généré automatiquement (affiché dans la console)
# Pour la production, définissez un token personnalisé
AUTH_TOKEN=your-secret-token-here

# ============================================
# Configuration LLM pour le client LLM-MCP
# ============================================
# Provider LLM: 'mistral' ou 'gemini'
LLM_PROVIDER=mistral

# Clé API Mistral (si provider=mistral et USE_OPENROUTER=false)
# Obtenez-la depuis https://console.mistral.ai/
MISTRAL_API_KEY=your_mistral_api_key_here

# Clé API Gemini (si provider=gemini et USE_OPENROUTER=false)
# Obtenez-la depuis https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# Clé API OpenRouter (si USE_OPENROUTER=true)
# Obtenez-la depuis https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Utiliser OpenRouter comme proxy (true/false)
USE_OPENROUTER=false

# Modèle LLM à utiliser (optionnel)
# Pour Mistral direct: mistral-small-latest, mistral-medium-latest, mistral-large-latest
# Pour Gemini direct: gemini-2.5-flash, gemini-2.5-pro
# Pour OpenRouter: mistralai/mistral-small-latest, google/gemini-2.5-flash, etc.
LLM_MODEL=mistral-small-latest

# ============================================
# Configuration pour le client MCP générique
# ============================================
# URL du serveur MCP (par défaut: http://localhost:3000/mcp)
# Peut être n'importe quel serveur MCP compatible
MCP_SERVER_URL=http://localhost:3000/mcp

# Token d'authentification pour le serveur MCP (optionnel)
# Utilise AUTH_TOKEN si MCP_AUTH_TOKEN n'est pas défini
MCP_AUTH_TOKEN=your-mcp-auth-token-here
